"""
RAGæ ¸å¿ƒæœåŠ¡ï¼ˆç®€åŒ–ç‰ˆï¼‰
é›†æˆï¼šç™¾åº¦åƒå¸†API + å…³é”®è¯æœç´¢ + å†…å­˜ç¼“å­˜ + é•¿æœŸè®°å¿†
"""

from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import requests
import json
import time
import re
from collections import defaultdict

from core.config import settings


class BaiduAuth:
    """ç™¾åº¦åƒå¸†OAuth 2.0è®¤è¯"""

    _access_token = None
    _token_expires_at = 0

    @classmethod
    def get_access_token(cls) -> str:
        """è·å–è®¿é—®ä»¤ç‰Œï¼ˆè‡ªåŠ¨åˆ·æ–°ï¼‰"""
        now = int(time.time())

        # å¦‚æœä»¤ç‰Œè¿˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
        if cls._access_token and now < cls._token_expires_at - 60:
            return cls._access_token

        # è·å–æ–°ä»¤ç‰Œ
        url = settings.BAIYUN_AUTH_URL
        params = {
            "grant_type": "client_credentials",
            "client_id": settings.BAIYUN_ACCESS_KEY,
            "client_secret": settings.BAIYUN_SECRET_KEY
        }

        try:
            response = requests.post(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()

            cls._access_token = data.get("access_token")
            expires_in = data.get("expires_in", 2592000)
            cls._token_expires_at = now + expires_in

            print(f"âœ… ç™¾åº¦åƒå¸†Access Tokenåˆ·æ–°æˆåŠŸ")
            return cls._access_token

        except Exception as e:
            print(f"âŒ ç™¾åº¦åƒå¸†è®¤è¯å¤±è´¥: {e}")
            raise


class BaiduEmbedding:
    """ç™¾åº¦åƒå¸†åµŒå…¥æ¨¡å‹ï¼ˆæš‚æ—¶ç¦ç”¨ï¼Œä½¿ç”¨å ä½ï¼‰"""

    def __init__(self):
        self.api_url = settings.EMBEDDING_API_BASE
        self.engine = settings.EMBEDDING_MODEL
        self.dimension = settings.MILVUS_DIMENSION

    async def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æ¡£å‘é‡ï¼ˆæš‚æœªå®ç°ï¼Œè¿”å›é›¶å‘é‡ï¼‰"""
        # ç®€åŒ–ç‰ˆï¼šä¸ä½¿ç”¨å‘é‡æœç´¢
        return [[0.0] * self.dimension] * len(texts)

    async def embed_query(self, text: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆæš‚æœªå®ç°ï¼Œè¿”å›é›¶å‘é‡ï¼‰"""
        return [0.0] * self.dimension


class BaiduChat:
    """ç™¾åº¦åƒå¸†å¯¹è¯æ¨¡å‹ï¼ˆCoding Plan Liteï¼‰"""

    def __init__(self):
        self.api_url = f"{settings.BAIYUN_API_BASE}/chat/{settings.CHAT_MODEL}"
        self.model = settings.CHAT_MODEL

    async def chat(
        self,
        messages: List[Dict],
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """å¯¹è¯ç”Ÿæˆ"""
        try:
            access_token = BaiduAuth.get_access_token()

            headers = {
                "Content-Type": "application/json"
            }

            payload = {
                "messages": messages,
                "temperature": temperature,
                "top_p": 0.8,
                "penalty_score": 1.0,
                "disable_search": False,
                "enable_citation": False
            }

            url = f"{self.api_url}?access_token={access_token}"

            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()

            data = response.json()

            if "error_code" in data:
                error_msg = data.get("error_msg", "æœªçŸ¥é”™è¯¯")
                print(f"âŒ Chat APIé”™è¯¯: {error_msg}")
                return f"æŠ±æ­‰ï¼ŒAIå›å¤ç”Ÿæˆå¤±è´¥ï¼š{error_msg}"

            result = data.get("result", "")
            return result

        except Exception as e:
            print(f"âŒ Chat APIè°ƒç”¨å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼ŒAIå›å¤ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"


class SimpleMemoryCache:
    """ç®€å•çš„å†…å­˜ç¼“å­˜"""

    def __init__(self):
        self.cache = {}

    def get(self, key):
        return self.cache.get(key)

    def set(self, key, value, expire_seconds=None):
        self.cache[key] = value

    def delete(self, key):
        self.cache.pop(key, None)

    def clear_pattern(self, pattern):
        keys_to_delete = [k for k in self.cache.keys() if pattern in k]
        for k in keys_to_delete:
            del self.cache[k]


class KeywordSearchService:
    """å…³é”®è¯æœç´¢æœåŠ¡ï¼ˆæ›¿ä»£Milvusï¼‰"""

    def __init__(self, db):
        self.db = db
        self.cache = SimpleMemoryCache()

    async def insert_chunks(
        self,
        chunks: List[Dict[str, Any]]
    ) -> int:
        """å­˜å‚¨æ–‡æ¡£å—åˆ°æ•°æ®åº“"""
        # æ–‡æ¡£å—å·²ç»å­˜å‚¨åœ¨PostgreSQL/MongoDBä¸­
        # è¿™é‡Œåªæ˜¯è®°å½•æ’å…¥æˆåŠŸ
        print(f"âœ… å­˜å‚¨ {len(chunks)} ä¸ªæ–‡æ¡£å—åˆ°æ•°æ®åº“")
        return len(chunks)

    async def search(
        self,
        query: str,
        user_id: int,
        top_k: int = 5,
        document_ids: List[int] = None
    ) -> List[Dict[str, Any]]:
        """å…³é”®è¯æœç´¢"""
        # æå–æŸ¥è¯¢ä¸­çš„å…³é”®è¯
        keywords = self._extract_keywords(query)
        print(f"ğŸ” å…³é”®è¯: {keywords}")

        # ä»æ•°æ®åº“ä¸­æœç´¢åŒ…å«å…³é”®è¯çš„æ–‡æ¡£å—
        results = await self._search_in_database(keywords, user_id, document_ids, top_k)

        return results

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•åˆ†è¯ï¼ˆä¸­æ–‡+è‹±æ–‡ï¼‰
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[^\w\s]', '', text)
        # æŒ‰ç©ºæ ¼å’Œä¸­æ–‡åˆ†å‰²
        words = re.findall(r'[\w]+|[\u4e00-\u9fff]+', text)
        # è¿‡æ»¤åœç”¨è¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
        stop_words = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'æˆ‘', 'ä½ ', 'ä»–', 'è¿™', 'é‚£', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•'}
        keywords = [w for w in words if len(w) > 1 and w not in stop_words]
        return keywords

    async def _search_in_database(
        self,
        keywords: List[str],
        user_id: int,
        document_ids: List[int],
        top_k: int
    ) -> List[Dict[str, Any]]:
        """åœ¨æ•°æ®åº“ä¸­æœç´¢"""
        # è¿™é‡Œç®€åŒ–å®ç°ï¼šç›´æ¥è¿”å›ç©ºåˆ—è¡¨
        # å®é™…åº”è¯¥æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æ–‡æ¡£å—
        # ä»models.documentä¸­æŸ¥è¯¢æ–‡æ¡£ï¼Œç„¶ååŒ¹é…å†…å®¹

        print(f"âš ï¸  å…³é”®è¯æœç´¢æœªå®Œå…¨å®ç°ï¼Œè¿”å›ç©ºç»“æœ")
        return []


class RAGService:
    """RAGæ£€ç´¢å¢å¼ºç”ŸæˆæœåŠ¡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    def __init__(self, db):
        self.db = db
        self.embedding = BaiduEmbedding()
        self.chat = BaiduChat()
        self.search_service = KeywordSearchService(db) if not settings.ENABLE_MILVUS else None
        self.cache = SimpleMemoryCache()

    async def index_document(
        self,
        document_id: int,
        user_id: int,
        file_name: str,
        chunks: List[str]
    ) -> int:
        """ç´¢å¼•æ–‡æ¡£"""
        if not chunks:
            return 0

        print(f"ğŸ“„ å¼€å§‹ç´¢å¼•æ–‡æ¡£: {file_name} ({len(chunks)} ä¸ªchunks)")

        # ç®€åŒ–ç‰ˆï¼šåªè®°å½•chunkæ•°é‡ï¼Œä¸ç”Ÿæˆå‘é‡
        chunk_data = [
            {
                "chunk_id": int(hash(f"{document_id}_{idx}") % (10 ** 9)),
                "user_id": user_id,
                "document_id": document_id,
                "file_name": file_name,
                "content": chunk
            }
            for idx, chunk in enumerate(chunks)
        ]

        # æ’å…¥åˆ°æœç´¢æœåŠ¡
        count = await self.search_service.insert_chunks(chunk_data)

        # æ¸…é™¤ç¼“å­˜
        self._clear_search_cache(user_id)

        return count

    async def search(
        self,
        query: str,
        user_id: int,
        top_k: int = 5,
        document_ids: List[int] = None,
        use_cache: bool = False
    ) -> List[Dict[str, Any]]:
        """å…³é”®è¯æ£€ç´¢"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"search:{user_id}:{hash(query)}:{top_k}"
        if use_cache:
            cached = self.cache.get(cache_key)
            if cached:
                return cached

        # å…³é”®è¯æœç´¢
        results = await self.search_service.search(query, user_id, top_k, document_ids)

        # ç¼“å­˜ç»“æœ
        if use_cache:
            self.cache.set(cache_key, results)

        print(f"ğŸ” æœç´¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…")
        return results

    async def chat(
        self,
        query: str,
        user_id: int,
        conversation_history: List[Dict],
        user_prompt: str = "",
        document_ids: List[int] = None,
        temperature: float = 0.7
    ) -> Dict[str, Any]:
        """RAGå¯¹è¯"""
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        search_results = await self.search(query, user_id, document_ids=document_ids)

        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = ""
        if search_results:
            context += "**ä»¥ä¸‹æ˜¯ä»æ–‡æ¡£ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼š**\n\n"
            for idx, result in enumerate(search_results, 1):
                context += f"[æ¥æº{idx}] {result['file_name']}\n"
                context += f"{result['content']}\n\n"
        else:
            context = "ï¼ˆæ–‡æ¡£æ£€ç´¢æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼ŒåŸºäºæˆ‘çš„çŸ¥è¯†åº“å›ç­”ï¼‰"

        # 3. æ·»åŠ ç”¨æˆ·æç¤º
        if user_prompt:
            context += f"\n**ç”¨æˆ·è¡¥å……è¯´æ˜ï¼š**\n{user_prompt}\n"

        # 4. æ„å»ºæ¶ˆæ¯å†å²
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼ä¸šçŸ¥è¯†åŠ©æ‰‹ï¼Œæ“…é•¿å›ç­”é—®é¢˜ã€‚

**å·¥ä½œåŸåˆ™ï¼š**
1. ä¼˜å…ˆåŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ä¿¡æ¯å›ç­”
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¯ä»¥åŸºäºä½ çš„çŸ¥è¯†åº“å›ç­”
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€ä¸“ä¸š
4. ä¿æŒä¸å¯¹è¯å†å²çš„ä¸€è‡´æ€§

**å½“å‰ä¸Šä¸‹æ–‡ï¼š**
{context}

ç°åœ¨å¼€å§‹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""

        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ å†å²å¯¹è¯ï¼ˆæœ€è¿‘10è½®ï¼‰
        for msg in conversation_history[-10:]:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", "")
            })

        # æ·»åŠ å½“å‰é—®é¢˜
        messages.append({"role": "user", "content": query})

        # 5. ç”Ÿæˆå›å¤
        print(f"ğŸ’¬ å¼€å§‹ç”Ÿæˆå›å¤...")
        response = await self.chat.chat(messages, temperature)
        print(f"âœ… å›å¤ç”Ÿæˆå®Œæˆ")

        return {
            "response": response,
            "sources": [
                {
                    "file_name": r.get("file_name", "æœªçŸ¥"),
                    "content": r.get("content", ""),
                    "score": 1.0
                } for r in search_results
            ],
            "context": context
        }

    def _clear_search_cache(self, user_id: int):
        """æ¸…é™¤æœç´¢ç¼“å­˜"""
        self.cache.clear_pattern(f"search:{user_id}:")


class MemoryService:
    """é•¿æœŸè®°å¿†æœåŠ¡ï¼ˆå‚è€ƒOpenClawï¼‰"""

    def __init__(self, db):
        self.db = db

    async def add_memory(
        self,
        user_id: int,
        content: str,
        importance: float = 0.5,
        category: str = None,
        source: str = "manual",
        tags: List[str] = None
    ) -> Dict:
        """æ·»åŠ é•¿æœŸè®°å¿†"""
        from models.memory import Memory

        memory = Memory(
            user_id=user_id,
            content=content,
            importance=importance,
            category=category or "general",
            source=source,
            tags=tags or [],
            expires_at=self._calculate_expiry(importance)
        )

        self.db.add(memory)
        await self.db.commit()
        await self.db.refresh(memory)

        return {
            "id": memory.id,
            "content": memory.content,
            "importance": memory.importance,
            "category": memory.category,
            "tags": memory.tags,
            "expires_at": memory.expires_at
        }

    async def retrieve_memories(
        self,
        user_id: int,
        query: str = None,
        category: str = None,
        min_importance: float = 0.7,
        limit: int = 5
    ) -> List[Dict]:
        """æ£€ç´¢é•¿æœŸè®°å¿†"""
        from sqlalchemy import select, or_
        from models.memory import Memory

        query_builder = select(Memory).where(
            Memory.user_id == user_id,
            Memory.is_active == True,
            Memory.importance >= min_importance
        )

        if category:
            query_builder = query_builder.where(Memory.category == category)

        # å…³é”®è¯æœç´¢
        if query:
            words = query.split()
            conditions = [Memory.content.contains(word) for word in words]
            query_builder = query_builder.where(or_(*conditions))

        query_builder = query_builder.order_by(Memory.importance.desc()).limit(limit)

        result = await self.db.execute(query_builder)
        memories = result.scalars().all()

        # æ›´æ–°è®¿é—®ç»Ÿè®¡
        for memory in memories:
            memory.access_count += 1
            memory.last_accessed = datetime.utcnow()

        await self.db.commit()

        return [
            {
                "id": m.id,
                "content": m.content,
                "importance": m.importance,
                "category": m.category,
                "tags": m.tags,
                "source": m.source,
                "access_count": m.access_count
            }
            for m in memories
        ]

    def _calculate_expiry(self, importance: float):
        """æ ¹æ®é‡è¦æ€§è®¡ç®—è¿‡æœŸæ—¶é—´"""
        if importance > 0.9:
            return datetime.utcnow() + timedelta(days=180)
        elif importance > 0.8:
            return datetime.utcnow() + timedelta(days=90)
        elif importance > 0.7:
            return datetime.utcnow() + timedelta(days=30)
        elif importance > 0.6:
            return datetime.utcnow() + timedelta(days=7)
        else:
            return None

    async def cleanup_expired_memories(self, user_id: int = None):
        """æ¸…ç†è¿‡æœŸè®°å¿†"""
        from sqlalchemy import select
        from models.memory import Memory

        query_builder = select(Memory).where(
            Memory.expires_at < datetime.utcnow(),
            Memory.is_active == True
        )

        if user_id:
            query_builder = query_builder.where(Memory.user_id == user_id)

        result = await self.db.execute(query_builder)
        expired_memories = result.scalars().all()

        for memory in expired_memories:
            memory.is_active = False

        await self.db.commit()

        return len(expired_memories)
